import "./Read.css";

function Read() {
    return (<div id="read">
        <p class="c12"><span class="c0">The Ethics of Digital Data Privacy</span></p>
        <ol class="c9 lst-kix_mwkz994mz8sp-0 start" start="1">
            <li class="c15 li-bullet-0">
                <h1 id="h.o2qxgxl8k1hz" style={{display: "inline"}}><span class="c2">Introduction</span></h1>
            </li>
        </ol>
        <p class="c1 c6"><span class="c0">All humans are inherently evil. Without control and authority, people will
            undoubtedly fight for power over one another using whatever means necessary. These sweeping generalizations
            are one of the major roadblocks that slow the progress of our society. Leaders use people&rsquo;s fear of
            themselves to justify regulations that restrict the minds of innovative thinkers. Without any trust in the
            good intentions of other people, we can never achieve systematic progress. At the same time, it would be
            unwise of individuals to hand over their autonomy to governments and organizations because it would lead to
            an Orwellian world void of any sense of individuality. In such a world, individuals would hardly feel the
            benefits of advancements, which would defeat the point of making those advancements in the first place. One
            of the primary duties of government in society is to establish an appropriate balance between the
            contrasting altruistic and selfish natures of human beings. In a world where technologies are created every
            day and where companies can learn more about your life than your own family members, this role is more
            important than ever.</span></p>
        <p class="c1 c6"><span class="c7">In the novel </span><span class="c7 c8">1984</span><span class="c0">, George
            Orwell envisions a world devoid of privacy and individuality. In the story, the population is constantly
            monitored and is held in check by the fear of intense punishment whenever they even slightly step out of
            line. In the real world, it would be difficult for any party or organization to reach this power level
            without facing severe resistance from citizens. However, if an organization were to watch people without
            their knowledge or consent, they could potentially gain Orwellian levels of power unbeknownst to the general
            population.</span></p>
        <p class="c1 c6"><span class="c7">As prominent technology corporations develop powerful methods of utilizing data to
            fulfill their desires, the value and power of data as an asset continue to expand. At the beginning of 2024,
            Reddit announced that it was selling access to its collection of user-generated data to several large
            artificial intelligence companies, including Google (Dave). This transaction is just one instance of
            data&rsquo;s transformation into a weapon companies pay hundreds of millions for. As companies become more
            and more capable of leveraging Orwellian powers, the urgency for regulations on the collection and usage of
            data grows equally. Even back in 2012, public panic erupted in response to a </span><span class="c7">Forbes
                article claiming that Target had developed an algorithm that could accurately predict if a customer was
                pregnant (Hill)</span><span class="c0">. Although the article has been criticized for shaky sources and
                    reasoning, this scare still highlights the limitless potential of corporate surveillance. A decade ago,
                    companies were already starting to identify extremely intimate details in peoples&rsquo; lives, such as
                    pregnancy, to deliver customized advertisements and coupons to their targets. With the exponential nature of
                    technological advancements, there is no telling the power companies could have over their customers.</span>
        </p>
        <p class="c1 c6"><span class="c7">In the United States, there are currently no detailed federal data privacy laws,
            and only a few states are just beginning to develop regulations controlling what companies can do with user
            data (Halladay)</span><span class="c7">. Hundreds of millions of consumers are powerless against corporate
                manipulation through their personal data. It is crucial to establish regulations that protect consumers of
                digital products while maintaining the liberties of companies to </span><span class="c7">gift</span><span
                    class="c0">&nbsp;innovations to the world. These regulations will be placed on technology companies, so
                before any legislation can be produced, the extent to which companies are responsible for protecting their
                users&rsquo; data must be established, which is the goal of this paper. Companies should be held responsible
                for transparent data collection practices, and for preventing harm to their consumers, and nothing more.
                These responsibilities then must be translated into a legislature that is effectively enforced, and only
                then will society reap the benefits of responsible corporate decision-making in the digital world.</span>
        </p>
        <ol class="c9 lst-kix_mwkz994mz8sp-0" start="2">
            <li class="c15 li-bullet-0">
                <h1 id="h.y7mr68jagcyu" style={{display: "inline"}}><span class="c2">Data Collection</span></h1>
            </li>
        </ol>
        <p class="c1 c6"><span class="c7">Data collection refers to gathering information that falls under a defined set of
            variables. Large technology companies devote enormous amounts of resources to their data collection methods,
            in which the data is often collected from their users. They do this through several methods which can fall
            into two general categories: direct inputs from the user and passive observance of their behavior. For
            example, when a site requests that users type their personal information, such as a birthdate or address,
            they provide data directly to the company. In this case, the user has a relatively large amount of control
            over the data collection process. On the other hand, </span><span class="c7">sites such as Amazon or
                Instagram often monitor a user&rsquo;s browsing or purchasing habits to provide custom advertisements and
                recommendations (Graham)</span><span class="c0">. This is an example of passive observation or data
                    surveillance, where the user has less control or knowledge of the data collection process. These situations
                    vary ethically and as such must be handled separately.</span></p>
        <p class="c1 c6"><span class="c0">When data is collected through direct interactions between a customer and the
            company, there should only be limited regulations that the company must follow. The user has full control
            over what information they provide, so if the company requests inappropriate or unnecessary information,
            they can just refuse to use the service. Companies will naturally be restricted to only asking for
            information that customers will usually be willing to provide, so external regulations are unnecessary.
            Regulating this form of data collection could even harm the companies if laws were too constrictive, as it
            could prevent companies from accessing data that could benefit their business or possible innovative
            developments.</span></p>
        <p class="c1 c6"><span class="c0">One requirement that should be placed on businesses when directly collecting data
            from customers is transparency about the purpose of collecting the information. It would be unethical for a
            company to deceive customers about their services to manipulate them into handing over sensitive
            information. Regulators should require companies to only collect information that is at least tangentially
            related to their product unless they provide exact details about how the information will be used. For
            example, suppose Facebook were to ask customers for information unrelated to the social media aspect of
            their business, such as social security numbers. In that case, they would also need to describe their
            reasons for collecting that information in detail. However, as long as the collection method is not
            blatantly concealing the purpose for requiring the information, companies should be free to collect whatever
            information they want through direct inputs from their users.</span></p>
        <p class="c1 c6"><span class="c0">There must be much stricter policies enforced on companies that want to passively
            monitor people&rsquo;s behavior. Both public organizations and private companies have developed technology
            that enables them to conduct digital surveillance without the knowledge of those being monitored. These
            methods of data collection range from corporate surveillance of employees to software such as Pegasus, which
            &ldquo;gives the operator access to the microphone, camera, GPS data, passwords, audio and visual
            recordings, email, and voicemails on the unsuspecting user&rsquo;s infected phone&rdquo; (Belmonte). Such
            advancements are a threat to the human right to privacy.</span></p>
        <p class="c1 c6"><span class="c0">To preserve this basic human right, companies should be forbidden from passively
            collecting information from customers unless they provide an explicit explanation about the methods of
            collection. This allows the customers to take appropriate measures to protect their information if they so
            desire. The Internet Encyclopedia of Philosophy states that &ldquo;privacy affords us the space to be
            ourselves and to define ourselves through giving us a degree of autonomy&rdquo; (Macnish). Relinquishing
            behavioral information to companies has the possibility of destroying our autonomy if the companies can use
            that information to successfully manipulate our actions. This is why digital data surveillance is unethical
            if the ones being watched have no say in the matter.</span></p>
        <ol class="c9 lst-kix_mwkz994mz8sp-0" start="3">
            <li class="c3 li-bullet-0">
                <h1 id="h.3cs4aofnxqjm" style={{display: "inline"}}><span class="c2">Data Sharing</span></h1>
            </li>
        </ol>
        <p class="c1 c6"><span class="c0">Data that has been collected from users is useless until something is done with
            it. Companies can use data for countless purposes, from optimizing marketing campaigns to minimizing
            internal costs and inefficiencies. There are even companies known as &ldquo;data brokers&rdquo; that collect
            and aggregate data for the sole purpose of reselling it to larger firms. Data brokers digitally profile
            nearly every person in America without their knowledge or consent, then distribute it for a profit (EPIC).
            There are very few federal laws outlining information privacy policy, which includes not only how data is
            collected but also how it is used, shared, and stored (Bloomberg). This lack of regulation enables the
            existence of data brokers and demands a discussion on the ethics of data usage by companies.</span></p>
        <p class="c1 c6"><span class="c0">One company that has become infamous for its numerous infringements upon
            users&rsquo; privacy is Facebook. For example, back in 2007, Facebook launched a new program called the
            Facebook Platform that granted outside developers access to members&rsquo; information so that they could
            create applications for Facebook users (Rubinstein). From a computer programmer&rsquo;s perspective, this
            was an exhilarating opportunity to develop exciting new programs. However, Facebook&rsquo;s limited
            safeguards protecting users&rsquo; data from the developers were less appealing to their customers. Canadian
            regulators eventually investigated these issues, but this clearly did not lead to Facebook gaining a deeper
            understanding of the ethics of data usage, as they have faced a multitude of lawsuits and privacy
            controversies since this event. For example, the Federal Trade Commission has taken action against Facebook
            multiple times in only the past several years (Federal Trade Commission).</span></p>
        <p class="c1 c6"><span class="c0">The Facebook Platform and data brokers are two of many instances where companies
            have shared users&rsquo; data with outside entities for their own use. These practices are unethical when
            the user is not aware of where their data ends up because it breaks the trust between the primary company
            and the customer. Users trust Facebook to use their data to provide a better experience within
            Facebook&rsquo;s own product, but that trust does not automatically extend to the developers that Facebook
            shares the data with. Technology companies should be required to obtain specific consent from their users
            about exactly what information they are allowed to share with external entities. Additionally, they should
            be held accountable for the actions of these third-party entities in case they utilize the data for
            malicious purposes. This will incentivize companies such as Facebook to only allow trustworthy individuals
            and organizations to access user data.</span></p>
        <ol class="c9 lst-kix_mwkz994mz8sp-0" start="4">
            <li class="c3 li-bullet-0">
                <h1 id="h.fmw2673zoe3y" style={{display: "inline"}}><span class="c14">Data Usage</span></h1>
            </li>
        </ol>
        <p class="c1 c6"><span class="c0">The countless complaints against businesses for their use of data demonstrates
            that trust between a company and its users is not sufficient to convince companies to maintain ethical data
            practices. There must be regulations specifying what companies can do with user data, which will be built
            upon a moral foundation. This foundation will assume that the data was collected in an appropriate manner,
            and that the company is using the data internally rather than sharing it with another organization.</span>
        </p>
        <p class="c1 c6"><span class="c0">Once again using Facebook as an example, users of the social media site are
            motivated to share their data with Facebook in order to reap the benefits of increased visibility and
            accessibility through the site, which is the primary purpose of the platform. In doing so, the users are
            trusting Facebook to not use the data they provide in any way that would bring them harm. This harm can come
            in many forms, as malicious or ignorant organizations can use data in many ways. If a Facebook user&rsquo;s
            address is leaked to the wrong people, it could put them in physical danger by revealing their location. A
            data leak could also put a user at risk for financial harm if the leak leads to them losing money. Both
            public and private establishments make use of data practices that are especially detrimental to lower income
            individuals. Such practices prevent these individuals from acquiring jobs, fair interest rates, rapid police
            responses, and have even been proven to show bias when determining criminal sentencing or bail (Belmonte).
            Beyond the potential for harm, many users do not want any corporation or organization to have access to
            their details due to their personal beliefs, which must be respected. To prevent any of these injurious
            effect from occurring, companies must put together an accessible disclosure detailing how they use any data
            they collect. The disclosure should also outline any possible risks customers could face if they chose to
            share their information.</span></p>
        <ol class="c9 lst-kix_mwkz994mz8sp-0" start="5">
            <li class="c3 li-bullet-0">
                <h1 id="h.k2j07pd66v06" style={{display: "inline"}}><span class="c2">Legislation</span></h1>
            </li>
        </ol>
        <p class="c1 c6"><span class="c14">Although discussions about the ethics of data collection and usage are an
            essential step in the journey towards a balanced society, they are not enough to effect meaningful change.
            In a capitalist economy, firms are motivated by profit, not by the morality of their decisions (</span><span
                class="c7">Dolan)</span><span class="c2">. The government must implement the moral principles outlined
                    previously into physical laws that will causes businesses to adjust their behavior and policies regarding
                    digital data privacy. This paper intends to serve as motivation for the creation of deeper regulations in
                    the field of data privacy as well as a basis for how this could be accomplished.</span></p>
        <p class="c1 c6"><span class="c2">A complete digital data privacy law would have to address at minimum the four
            topics touched upon in this paper. These include direct data collection, data surveillance, data sharing,
            and data usage. The specific content of the law would model the ethical guidelines discussed throughout the
            paper, and would define limits to how companies can collect, use, and share data in different situations. It
            would also discuss the interactions between firms and consumers, and establish requirements for businesses
            to communicate their methods, purposes, and policies relating to users&rsquo; data.</span></p>
        <p class="c1 c6"><span class="c2">Besides drafting the contents of the law, law makers would also have to determine
            punishments and methods of enforcement. These have both proven to be difficult to get right in the corporate
            world, since large businesses and wealthy individuals are known to be exceptional at skirting the law and
            escaping punishment. In addition to imposing heavy fines and sanctions for violations, the government could
            punish uncooporative businesses by making some of the sensitive company data publicly available. This is
            admittedly a rather extreme solution, but it would give corporations a taste of their own medicine should
            they neglect to give the proper consideration to protecting their users&rsquo; data.</span></p>
        <p class="c1 c6"><span class="c2">Identifying companies not complying with the law is an even more daunting task.
            The simplest method is to rely on consumer complaints, but this would not cover cases where corporations are
            intentionally deceiving consumers and hiding information. Deeper investigations would have to be made into
            the largest or most suspicious companies, but even then, details will be missed and the evidence must be
            conclusive. Another solution would be to make the fines and punishments so severe that no company would dare
            risk breaking the law.</span></p>
        <ol class="c9 lst-kix_mwkz994mz8sp-0" start="6">
            <li class="c3 li-bullet-0">
                <h1 id="h.ze3dbwnhw3jl" style={{display: "inline"}}><span class="c2">Conclusion</span></h1>
            </li>
        </ol>
        <p class="c1 c6"><span class="c14">Ethical discussions and the production of legislation concerning personal data
            privacy in this new digital world are necessary for ensuring the safety of individuals and the prosperity of
            society. We must decide upon an appropriate balance of power between technology companies and their
            customers. We are entering a new era of technology with thrilling possibilities for novel developments, but
            the threat of complete corporate surveillance and control also looms. With the guidelines and proposals put
            forth in this paper, we can steer towards a better future for humanity.</span>
            <hr style={{"page-break-before": "always", display: "none"}}/>
        </p>
        <hr />
        <h1 class="c16" id="h.z84n5azud8t"><span class="c2">Works Cited</span></h1>
        <p class="c1 c5"><span class="c7">Belmonte, Laura. &ldquo;Can Human Rights Survive Technology?&rdquo;, Diplomatic
            History, vol. 47, no. 1, 2023, pp. 1&ndash;18, </span><span class="c11"><a class="c4"
                href="https://www.google.com/url?q=https://doi.org/10.1093/dh/dhac079&amp;sa=D&amp;source=editors&amp;ust=1715050435358304&amp;usg=AOvVaw0zrNIe73xLDNQbxdY_HrWj">https://doi.org/10.1093/dh/dhac079</a></span>
        </p>
        <p class="c1 c5"><span class="c7">Bloomberg. &quot;Consumer Data Privacy Laws.&quot; Bloomberg Law,
            pro.bloomberglaw.com/insights/privacy/consumer-data-privacy-laws/. Accessed 24 Apr. 2024.</span></p>
        <p class="c1 c5"><span class="c0">Dave, Paresh. &ldquo;Reddit&rsquo;s Sale of User Data for AI Training Draws FTC
            Inquiry.&rdquo; Wired, Conde Nast, 15 Mar. 2024,
            www.wired.com/story/reddits-sale-user-data-ai-training-draws-ftc-investigation/. </span></p>
        <p class="c1 c5"><span class="c0">Dolan, Brian. &quot;Main Characteristics of Capitalist Economies.&quot; Edited by
            Michael J. Boyle and Melody Kazel. Investopedia, Dotdash Meredith, 8 Feb. 2023,
            www.investopedia.com/articles/investing/102914/main-characteristics-capitalist-economies.asp#toc-the-bottom-line.
            Accessed 24 Apr. 2024.</span></p>
        <p class="c1 c5"><span class="c0">EPIC. &quot;Data Brokers.&quot; Electric Privacy Information Center,
            epic.org/issues/consumer-privacy/data-brokers/. Accessed 24 Apr. 2024.</span></p>
        <p class="c1 c5"><span class="c7">Federal Trade Commission. &ldquo;FTC Proposes Blanket Prohibition Preventing
            Facebook from Monetizing Youth Data&rdquo;, May 2023, </span><span class="c11"><a class="c4"
                href="https://www.google.com/url?q=https://www.ftc.gov/news-events/news/press-releases/2023/05/ftc-proposes-blanket-prohibition-preventing-facebook-monetizing-youth-data&amp;sa=D&amp;source=editors&amp;ust=1715050435359054&amp;usg=AOvVaw0RVNAZ2E7tJ5KlXmEZObtA">https://www.ftc.gov/news-events/news/press-releases/2023/05/ftc-proposes-blanket-prohibition-preventing-facebook-monetizing-youth-data</a></span>
        </p>
        <p class="c1 c5"><span class="c0">Graham, Jefferson. &quot;Amazon Is Watching, Listening and Tracking You.
            Here&#39;s How to Stop It.&quot; Phys.org, 27 June 2019, phys.org/news/2019-06-amazon-tracking.html.
            Accessed 24 Apr. 2024.</span></p>
        <p class="c1 c5"><span class="c0">Halladay, Kerry. &quot;Data Privacy Laws Every Company Should Know.&quot; Built
            In, 16 Nov. 2022, builtin.com/articles/us-data-privacy-laws. Accessed 24 Apr. 2024.</span></p>
        <p class="c1 c5"><span class="c7">Hill, Kashmir. &quot;How Target Figured out a Teen Girl Was Pregnant before Her
            Father Did.&quot; Forbes, 16 Feb. 2012,
            www.forbes.com/sites/kashmirhill/2012/02/16/how-target-figured-out-a-teen-girl-was-pregnant-before-her-father-did/?sh=169381476668.
            Accessed 24 Apr. 2024.</span></p>
        <p class="c1 c5"><span class="c7">Johnston, Kevin, et al. &ldquo;Social Capital: The Benefit of Facebook
            &lsquo;Friends.&rsquo;&rdquo; Behaviour &amp; Information Technology, vol. 32, no. 1, Jan. 2013, pp.
            24&ndash;36. EBSCOhost, </span><span class="c11"><a class="c4"
                href="https://www.google.com/url?q=https://doi.org/10.1080/0144929X.2010.550063&amp;sa=D&amp;source=editors&amp;ust=1715050435359483&amp;usg=AOvVaw30wluNYCvO4dw36Aa_3dEp">https://doi.org/10.1080/0144929X.2010.550063</a></span><span
                    class="c0">.</span></p>
        <p class="c1 c5"><span class="c0">Macnish, Kevin. &quot;Surveillance Ethics.&quot; Internet Encyclopedia of
            Philosophy, iep.utm.edu/surv-eth/. Accessed 24 Apr. 2024.</span></p>
        <p class="c1 c5"><span class="c0">Rubinstein, Ira S., and Nathaniel Good. &ldquo;Privacy by Design: A Counterfactual
            Analysis of Google and Facebook Privacy Incidents.&rdquo; Berkeley Technology Law Journal, vol. 28, no. 2,
            2013, pp. 1333&ndash;413. JSTOR, http://www.jstor.org/stable/24119897. Accessed 6 Mar. 2024.</span></p>
        <p class="c1 c5"><span class="c7">Sacasas, L. M. &ldquo;How Facebook Deforms Us.&rdquo; </span><span
            class="c7 c8">The New Atlantis</span><span class="c7">, no. 56, 2018, pp. 82&ndash;91. </span><span
                class="c7 c8">JSTOR</span><span class="c0">, http://www.jstor.org/stable/26498246. Accessed 6 Mar.
                    2024.</span></p>
        <p class="c1 c5"><span class="c7">Vishwanath, Arun, et al. &ldquo;How People Protect Their Privacy on Facebook: A
        </span><span class="c7">Cost&#8208;benefit</span><span class="c7">&nbsp;View.&rdquo; Journal of the Association
            for Information Science &amp; Technology, vol. 69, no. 5, May 2018, pp. 700&ndash;09. EBSCOhost,
            </span><span class="c11"><a class="c4"
                href="https://www.google.com/url?q=https://doi.org/10.1002/asi.23894&amp;sa=D&amp;source=editors&amp;ust=1715050435360051&amp;usg=AOvVaw2EYIp1fzQJ8Nbb4PkxUURJ">https://doi.org/10.1002/asi.23894</a></span><span
                    class="c0">.</span></p>
        <p class="c1 c5"><span class="c7">Wynn, Martin, and Peter Jones. &ldquo;Corporate Responsibility in the Digital
            Era.&rdquo; Information (2078-2489), vol. 14, no. 6, June 2023, p. 324. EBSCOhost, </span><span
                class="c11"><a class="c4"
                    href="https://www.google.com/url?q=https://doi.org/10.3390/info14060324&amp;sa=D&amp;source=editors&amp;ust=1715050435360249&amp;usg=AOvVaw3a4SoMqwmMCUq6fW_f3uY_">https://doi.org/10.3390/info14060324</a></span><span
                        class="c0">.</span></p>
    </div>);
}

export default Read;